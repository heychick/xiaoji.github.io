{"meta":{"title":"chick","subtitle":"","description":"","author":"wll","url":"114.55.64.175","root":"/"},"posts":[{"tags":[{"name":"tags","slug":"tags","permalink":"114.55.64.175/tags/tags/"}],"title":"Hadoop","date":"2019/11/19","text":"大数据大数据的5V特性是什么? Volume 大体量 Variety(多样性 Velocity 时效性 Veracity 准确性 Value 大价值 hadoop特点 高可靠,高扩展,高效性,高容错,低成本 hadoop常用组件 HDFS:Hadoop分布式文件系统 MapReduce:分布式计算框架 (map芮杜思) Yarn:集群资源管理系统 Zookeeper:分布式协作服务 hadoopjava-1.8.0-openjdk-devel , 解压hadoop-2.7.7,并移到/usr/local/hadoop查看rpm -ql java-1.8.0-openjdk 安装路径修改 /usr/local/hadoop/etc/hadoop/hadoop-env.sh export JAVA_HOME=”/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-2.b14.el7.x86_64/jre/“ export HADOOP_CONF_DIR=”/usr/local/hadoop/etc/hadoop” 检查是否正常/usr/local/hadoop/bin/hadoop version统计字段数量/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.7.jar wordcount 源文件 目标目录(自动创建) 完全分布式 /usr/local/hadoop/etc/hadoop/ -rw-r–r– 1 1000 ftp 774 7月 19 2018 core-site.xml 核心配置文件 -rw-r–r– 1 1000 ftp 4263 11月 19 11:57 hadoop-env.sh 环境变量 -rw-r–r– 1 1000 ftp 775 7月 19 2018 hdfs-site.xml HDFS配置文件 -rw-r–r– 1 1000 ftp 10 7月 19 2018 slaves 节点配置文件 设置环境4台主机 配置/etc/hosts192.168.1.30 docker1192.168.1.31 node1192.168.1.32 node2192.168.1.33 node3 禁用selinx 关闭防火墙 配置ssh秘钥1.30设置包含自己 注意事项 /etc/ssh/ssh_config Host * GSSAPIAuthentication yes StrictHostKeyChecking no #登录时去掉yes提示,秘钥保存 hoddp官方文档核心配置文件core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://docker1:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/var/hadoop&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; name关键字 value变量值 description描述 fs.defaultFS 默认存储系统 第一种本机写法file:/// 本机硬盘做为存储 第二种虚拟hdfs硬盘写法hdfs://namenode主机名:9000 hadoop.tmp.dir hadoop所有数据根目录 核心配置文件hdfs-site.xml &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;docker1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;docker1:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;description&gt;副本数&lt;/description&gt; &lt;/property&gt; 节点配置文件 node1 node2 node3 目录拷贝到其他机器 for i in node{1..3};do rsync -aXSH –delete /usr/local/hadoop ${i}:/usr/local/ &amp; done mkdir /var/hadoop 初始化 /usr/local/hadoop/bin/hdfs namenode -format 启动集群 /usr/local/hadoop/sbin/start-dfs.sh jsp验证角色(docker1会出现2个角色,node[1:3] 会出现1个datanode角色] jps 7233 SecondaryNameNode 7515 NameNode 9115 Jps [root@node2 ~]# jps 24912 Jps 24790 DataNode /usr/local/hadoop/bin/hdfs dfsadmin -reportLive datanodes (3): PS: 排错思路 检查/etc/hosts 检查jps是否安装 检查配置文件hadoop-env.sh slaves core-site.xml hdfs-site.xml 检查文件是否同步了 日志文件/usr/loacl/hadop/logshadoop组件-启动该进程用户-该程序的角色-哪台机器启动hadoop-root-namenode-docker1.log log 日志doop-root-namenode-docker1.out out 标准输出 ansible 脚本hadoop.yml#— hosts: hadooptasks: name: hostscopy: src=/etc/hosts dest=/etc/hosts name: yumyum: name: java-1.8.0-openjdk-devel state: latest","permalink":"114.55.64.175/2019/11/Hadoop/","photos":[]},{"tags":[],"title":"mysql","date":"2019/11/17","text":"配置文件 /etc/my.cn 数据存放路径 /var/lib/mysql 默认端口 3306 进程名 mysqld 传输协议 TCP 进程所有者 mysql 进程所属者 mysql 错误日志文件 /var/log/mysqld.log * 扩展 * /var/lib/mysql/库名/表名 user.frm 表头信息 user.ibd 表中数据和索引 首次登录密码在安装软件时随机生产随机密码存在日志文件/var/log/mysql.log查看随机密码 grep ‘password’ /var/log/mysqld.log mysql -h 数据库地址 -u用户 -p密码 修改root密码方式alter user root@”localhost” identified by “密码”;mysqladmin -uroot -p密码 password “密码” 修改密码策略 show variables like “%password%”; //查看变量 0 or LOW 长度 1 or MEDIUM(默认) 长度,数字,小写/大写,和特殊字符 2 or STRONG 长度,数字,小写/大写和特殊字符;字典文件 set global validate_password_policy=0;//修改密码策略 set global validate_password_length=6;//修改密码长度 * 永久配置 * vim /etc/my.cn validate_password_policy=0 validate_password_length=6 sql分类 DDL(定义) create alter frop DML(操作) insert update delete DCL(控制) grant revoke DTL(事物) commit rollback savepoint 库管理命令 show databases; //显示已有的库 select user(); //显示连接用户 select database(); //显示当前所在的库 use 库名; //切换库 show tables; //显示已有的表 create database 库名; //创建新库 drop database 库名; //删除库 表管理命令 create table 库名.表名 (字段名1 类型, 字段名2 类型) default charset=utf8; //指定中文字符集 永久配置 vim /etc/my.cnf character_set_server=utf8 show variables like ‘charac%’; 字符类型 定长char最大字符数255 变长varchar 按数据实际大小分配存储空间 varvhar 1--65532 大文本类型:text/blob 字符数大于65535存储时使用 数值类型 整数型 类型 名称 有符号范围 无符号范围 tinyint 微小整数 -128~127 0~255 malint 小整数 -32768~32767 0~65535 ediumint 中整型 int 大整型 bigint 极大整型 unsigned 使用无符号存储范围 #浮点型 float 单精度 double 双精度 blockchain日期类型 datetime 未给字段赋值时该值为null 1000-01-01 00:00:00~9999-12-31 23:59:59 timestamp 未给字段赋值时该值为系统当前时间 1970-01-01 00:00:00~2038-01-19 00:00:00 日期 date yyyymmdd 年 year yyyy 时间 time HH:MM:SS 时间函数 curtime() 获取当前的系统时间 curdate() 获取当前的系统日期 now() 获取当前系统日期和时间 year() 获取年 month() 获取月 day() 获取日 date() 获取日期 time() 获取时间 枚举类型 enum 单选 set 多选 ###Day02 约束条件 空null not null 非空 键值key 默认值default 额外设置 extra 修改表结构 添加新字段 alter table 表名 add 字段名 类型 约束条件 [after|firsh] 修改字段类型 alter table 表名 modify 字段名 类型 约束条件 [after|firsh] 修改字段名 alter table 表名 change 源字段 新字段 类型 约束条件; alter table t1 change id stu_id int ; 可以修改字段类型 alter table t1 change school xuexiao varchar(30) default &quot;tedua&quot;; 删除字段 alter table 表名 drop 字段名 删除多个字段 alter table 表名 drop 字段名,drop 字段名. 修改表名 alter table 表名 rename 新表名; INDEX普通索引 索引类型包括:Btree B+tree hash 优点: 通过创建唯一性索引,可以保证数据库表中每一行数据的唯一性 可以加快数据的查询速度 缺点: 当对表中的数据进行增删改的时候,索引也要动态的调整,降低了数据的维护速度 索引需要占用物理空间 index使用规则 一个表中可以有多个inxdex字段 字段的值允许重复,且可以赋null值 通常把做为查询条件的字段设置为index字段 index字段标志是MUL #已有表创建索引 create index 索引名 on 表名(字段名); #删除索引 drop index 索引名 on 表名; #查询索引信息 show index from 表名 index_type:BTREE 使用二叉树木算法 #创表时创建索引 create table t1 (name char(10), index(name)); primary key主键 使用规则 字段值不允许重复,且不允许赋值NULL值 一个表中只能有一个primary key字段 多个字段都可以做为主键,称为复合主键,必须一起创建. 主键字段的标志是PRI 主键通常与auto_increment连用 通常把表中唯一标识记录的字段设置为主键 在已有表中添加主键 alter table 表名 add primary key(字段名); 创建表时创建主键 #所有字段定义完，最后指定 mysql&gt; create table t9 (name char(10), name varchar(8),primary key(name)); #直接在字段定义时约束 mysql&gt; create table t8 (name char(10) primary key); #复合主键 mysql&gt; create table payy(name varchar(22),class varchar(22),pay enum(&quot;1&quot;,&quot;2&quot;) ,primary key (name,class,pay)); #删除主键,复合主键----删除后字段仍未非空 alter table t8 drop primary key; #自增长auto_increment mysql&gt; create table a(id int unsigned primary key auto_increment); #有自增长需要先删除自增长. alter table t3 modify id int not null; alter table t3 drop primary key; foreign key 外键 创建表时要指导引擎engine=innodb create table 表名 ( ...... foreign key(字段名) references 表名(字段名) on update cascade on delete cascade )engine=innodb; CREATE TABLE gz( gz_id int, gz float(7,2) , foreign KEY(gz_id) references yg(yg_id) //创建外键 ON UPDATE cascade ON DELETE cascade //同步更新、同步删除 )engine=innodb; 删除外键 alter table gz drop foreign key gz_ibfk_1; ###Day03 搜索路径 查看检索目录 show variables like &quot;secure_file_priv&quot;; /var/lib/mysql-files/ 修改检索目录 mkdir /myload chown mysql /myload vim /etc/my.cnf [mysqld] secure_file_priv=&quot;/myload&quot; systemctl restart mysqld 数据导入与导出 数据导入与导出 命令格式 mysql &gt; load data infile &quot;目录/文件名&quot; into table 库名 表名 fields terminated by &quot;分隔符&quot; lines terminated by &quot;\\n&quot;; 数据导入步骤 1.把系统文件拷贝到检索目录下 2.创建存储数据库和表 3.导入数据 4.查看数据 create table user ( name varchar(50),passwd char(1),uid int ,gid int,comment varchar(150),homedir varchar(150),shell varchar(50) ); mysql&gt; load data infile &quot;/myload/passwd&quot; into table db3.user fields terminated by &quot;:&quot; lines terminated by &quot;\\n&quot;; 数据导出 命令格式 select id,name,uid from user where id&lt;=10 into outfile &apos;/myload/user3.txt&apos; ; select id,name,uid from user where id&lt;=10 into outfile &apos;/myload/user3.txt&apos; fields terminated by &quot;###&quot; ; select id,name,uid from user where id&lt;=10 into outfile &apos;/myload/user3.txt&apos; fields terminated by &quot;###&quot; lines terminated by &quot;!!!&quot;; ###Day04 ####授权 grant 权限列表 on 库名 to 用户名@&quot;客户地址&quot; identified by &quot;密码&quot; with grant option; //with grant option 有授权权限,可选项 连接方式: 1.mysql -h192.168.4.50 -uyaya -p&apos;1qaz@WSX&apos; 2.select user(); 登录用户及客户端端地址 3.show grants; 用户显示自身访问权限 --权限列表 all 所有权限 usage 无权限 select,update,insert 个别权限 select,update(字段1,...字段N)指定字段 --库名 *.* 所有库所有表 库名.* 一个表 库名.表名 一张表 客户端地址 % 所有主机 192.168.4.% 网段内的所有主机 192.168.4.1 1台主机 localhost 数据库服务器本机 4.show grants for 用户名@&quot;客户端地址&quot;;管理员查看已有授权用户权限 5.set password=password(密码) ;授权用户连接后修改连接密码 6.set password for 用户名@&quot;客户端地址&quot;=password(&quot;密码&quot;); 管理员重置授权用户连接密码 set password for yaya@&apos;%&apos;=password(&quot;7ujm*IK&lt;&quot;); 7.drop user 用户名@&quot;客户端地址&quot; 删除授权用户(必须有管理员权限) 授权库 mysql库记录授权信息,主要表如下: user表 记录已有的授权(用户)及权限 db表 记录已有授权用户对(数据库)的访问权限 tables_priv表 记录已有授权用户对(表)的访问权限 columns_priv表 记录已有授权用户对(字段)的访问权限 #手动修改 update mysql.tables_priv set table_priv= &apos;select,insert,update,delete&apos; where user=&apos;admin&apos;; flush privileges; 撤销权限 命令格式: revoke 权限列表 on 库名.表 from 用户名@&quot;客户端地址&quot;; root密码(操作系统管理员root用户有权限配置) 修改数据库管理员root用户本机登录密码 mysqladmin -hlocalhost -uroot -p123qqq...A password &quot;1qaz@WSX&quot; 恢复数据库管理员root用户本机登录密码 1.停止mysql服务器程序 systemctl stop mysqld vim /etc/my.cnf skip-grant-tables PS:密码策略要注释掉 2.跳过授权表启动mysql服务程序 3.修改root密码 update mysql.user set authentication_string=password(&quot;7ujm*IK&lt;&quot;) where user=&quot;root&quot;; flush privileges; 4.以正常方式重启mysql服务程序 物理备份及恢复 物理备份 cp、tar 逻辑备份mysqldump(备份)，mysql(恢复) 备份操作 #!/bin/bash ssh root@192.168.4.51 systemctl stop mysqld ssh root@192.168.4.51 rm -rf /var/lib/mysql scp -r /var/lib/mysql root@192.168.4.51:/var/lib/mysql ssh root@192.168.4.51 chown -R mysql:mysql /var/lib/mysql/ ssh root@192.168.4.51 systemctl restart mysqld数据备份策略 完全备份:备份所有数据 增量备份：备份上次备份后，所产生的数据 差异备份:备份完全备份后,所有新产生的数据 完全备份及恢复 mysqldump -uroot -p密码 库名&gt;/目录 完全恢复 mysql -u -p 库名&lt;目录 ###Day05 什么是binlog日志？ 也称作二进制日志 mysql服务日志的一种 记录查询之外的所有sql命令 vim /etc/my.cnf log-bin #启用binlog日志 server_id=50 #指定值1~255 #查看日志 show master status; show master logs; #启用日志 ll /var/lib/mysql/主机名-bin* /var/lib/mysql/mysql1-bin.index #分析日志 show varialbes like &apos;binlog_format&apos;; 三种记录方式： 1.statement 报表模式 2.row 行模式 3.mixed 混合模式 #索引文件 1.修改日志文件路径 vim /etc/my.cnf log-bin=/log/zhj server_id=50 max_binlog_size=数值m ---指定日志文件容量,默认1G mkdir /log chown mysql /log 2.手动生成新的日志文件 mysqldump -uroot -p1qaz@WSX --flush-logs db5 &gt;/root/db5.sql flush logs; 或 mysql -uroot -p1qaz@WSX -e &quot;flush logs&quot; systemcrl restart nysqld 重启进程也会重新创建日志 3.删除已有的日志文件 purge master logs to &quot;zhj.000004&quot;; 删除指定编号之前的binlog日志文件 reset master; 重置日志文件###恢复数据 使用日志恢复数据 #mysqlbinlog 日志文件 | mysql -uroot -p1qaz@WSX mysqldump -uroot -p1qaz@WSX db3 &gt; /root/db3.sql mysql -uroot -p2wsx#EDC db3 &lt; /root/db3.sql mysqlbinlog zhj.000007 |mysql -uroot -p2wsx#EDC分析日志 show variables like &quot;binlog_format&quot;; /etc/my.cnf&quot; mysqlbinlog 选项 binlog日志文件名 | mysql -uroot -p密码 |选项|用户| |--|--| |start-datetime=&quot;yyyy-mm-dd hh:mm:ss&quot;|起始时间 |stop-datetime=&quot;yyyy-mm-dd hh:mm:ss&quot;|结束时间 |start-position=数字|起始偏移量 |stop-position=数字|结束偏移量 PS:偏移量 mysqlbinlog --start-position=296 --stop-position=1121 /root/zhj.000008 |mysql -uroot -p2wsx#EDC mysql -uroot -p2wsx#EDC -e &quot;select * from db3.ceshi;&quot; PS:时间 mysqlbinlog --start-datetime=&apos;2019-10-14 11:50:57&apos; --stop-datetime=&apos;2019-10-14 11:53:55&apos; zhj.000008 |mysql -uroot -p2wsx#EDC innobackupex 1.安装percona软件 2.完全备份与恢复 3.在完全备份恢复单张表数据 4.增量备份与恢复 2-1完全备份 常用选项 |含义 -- |-- --host|主机名 --user|用户名 --port|端口号 --password|密码 --databases|数据名 --no-timestamp|不用日期命名备份文件存储的子目录名 ps: databases=&quot;库名&quot; databases=&quot;库名1 库名2&quot; databases=&quot;库名.表&quot; ###完全备份操作 innobackupex --user root --password 1qaz@WSX /allbak --no-timestamp ###完全恢复操作 system stop mysqld rm -rf /var/lib/mysql/* innobackupex --apply-log /root/allbak/ #准备恢复数据 innobackupex --copy-back /root/allbak/ #恢复数据 chown -R mysql:mysql /var/lib/mysql/ systemctl restart mysqld mysql -uroot -p1qaz@WSX PS:可以查询准备恢复数据--&gt;恢复数据状态 cat /root/allbak/xtrabackup_checkpoints backup_type = full-prepared full-backuped 完全备份 incremental 增量备份 ###恢复单张表信息 1.删除表空间 mysql&gt;alter table db5.discard b tablespace; 2.导出表信息 innobackupex –apply-log –export /root/allbak/ 3.拷贝表信息文件到数据库目录下 cp /root/allbak/db5/b.{cfg,ibd,exp} /var/lib/mysql/db5/ 4.修改表信息文件的所有者及组用户 chown mysql:mysql /var/lib/mysql/db5/b.* 5.导入表空间 mysql&gt;alter table db5.b import tablespace; 6.删除数据库目录下的表信息文件 rm -rf /var/lib/mysql/db5/b.{cfg,exp} ###增量备份与恢复(不会锁表) 完全备份 innobackupex --user root --password 1qaz@WSX /fullbak --no-timestamp 增量备份(当前数据与上次数据对比) innobackupex --user --password --incremental 备份目录 --incremental-basedir=/上次备份文件 innobackupex --user root --password 1qaz@WSX --incremental /new1dir --incremental-basedir=/fullbak --no-timestamp innobackupex --user root --password 1qaz@WSX --incremental /new2dir --incremental-basedir=/new1dir --no-timestamp ##增量恢复 systemctl stop mysqld rm -rf /var/lib/mysql/* innobackupex --apply-log --redo-only /root/fullbak/ --incremental-dir=/root/new1dir innobackupex --apply-log --redo-only /root/fullbak/ --incremental-dir=/root/new2dir innobackupex --copy-back /root/fullbak/ chown -R mysql:mysql /var/lib/mysql systemctl start mysqld MYSQL主从同步 1.主从介绍 1实现数据自动同步的服务结构 主服务器:接受客户端访问连接 从服务器:自动同步主服务器数据 2.主从同步原理 主必须启用binlog日志 slave_IO:复制master主机binlog日志文件里的sql命令到本机的relay-log文件里 slave_sql:执行本机relay-log文件里的sql语句,实现与master数据一致 2.配置 主: vim /etc/my.cnf log-bin=master51 server_id=51 ##不允许与主库server_id相同 systemctl restart mysqld grant replication slave on *.* to repluser@&quot;%&quot; identified by &quot;1qaz@WSX&quot;; ps: replication slave 复制命令权限 从: mysqldump -uroot -p1qaz@WSX --master-data db5 &gt;/root/db5.sql mysqldump -uroot -p1qaz@WSX --master-data -A &gt; /root/all1.sql -A 导出所有库 scp /root/db5.sql root@192.168.4.52:/root/ grep master51 /root/db5.sql change master to master_host=&quot;192.168.4.51&quot;, master_user=&quot;repluser&quot;,master_password=&quot;1qaz@WSX&quot; , master_log_file=&quot;master51.000001&quot;,master_log_pos=441; master信息会自动保存到/var/lib/mysql/master.info文件 若更改主库信息时, 应先执行stop slave 修改后在执行start slave start slave; show slave status; Slave_IO_Running: Yes #IQ线程 Slave_SQL_Running: Yes #SQL线程 mysql -uroot -p1qaz@WSX -e &quot;show slave status\\G&quot;|grep -Ei &apos;yes|192.168.4.52&apos; 额外 mysql&gt; stop slave; mysql&gt; reset slave all; reset slave all;是清除从库的同步复制信息、包括连接信息和二进制文件名、位置。 从库上执行这个命令后，使用show slave status将不会有输出。 相关配置文件 文件名 说明 aster.info 主库信息 relay-log.info 中继日志信息 主机名-relay-bin.xxx 中继日志 主机名-relay-bin.index 索引文件 ####主从同步结构 配置一主多从结构 1.修改vim /etc/my.cnf 2.mysqldump -uroot -p1qaz@WSX --master-data -B ceshi db1 db5 &gt;/root/two.sql scp /root/two.sql root@192.168.4.53:/root [master-data]记录当前备份数据对应的日志信息 -B 多个库时条件 3.mysql -uroot -p1qaz@WSX &lt; two.sql; grep master two.sql 4.mysql&gt; change master to master_host=&apos;192.168.4.51&apos;,master_user=&quot;repluser&quot;,master_password=&quot;1qaz@WSX&quot;,master_log_file=&quot;master51.000002&quot;,master_log_pos=1793; 5.mysql&gt; start slave; 6.show slave status; 配置主从从结构 删除53之前的数据 rm -rf relay-log.info master.info rm -rf mysql4* vim /etc/my.cnf log-bin=master53 server_id=53 grant replication slave on *.* to repluser@&quot;%&quot; identified by &apos;1qaz@WSX&apos;; 54为主从 53主--&gt; 54从(主)--&gt;&gt;55--&gt;从 54操作 vim /etc/my.cnf log-bin=master54 server_id=54 log_slave_updates //允许级联复制 grant replication slave on *.* to repluser@&quot;%&quot; identified by &apos;1qaz@WSX&apos;; change master to master_host=&apos;192.168.4.53&apos;,master_user=&quot;repluser&quot;,master_password=&quot;1qaz@WSX&quot;,master_log_file=&apos;master53.000001&apos;,master_log_pos=441; 指定端口Master_Port=端口 start slave; show slave status; 55操作 vim /etc/my.cnf server_id=55 mysql&gt; change master to master_host=&quot;192.168.4.54&quot;,master_user=&apos;repluser&apos;,master_password=&apos;1qaz@WSX&apos;,master_log_file=&quot;master54.000001&quot;,master_log_pos=441; ####复制模式 查看是否允许动态加载模块(YES) show variables like &apos;have_dynamic_loading&apos;; 加载模块 #主模块 install plugin rpl_semi_sync_master SONAME &quot;semisync_master.so&quot;; #从模块 install plugin rpl_semi_sync_slave SONAME &quot;semisync_slave.so&quot;; #查看模块是否加载成功(ACTIVE) select PLUGIN_NAME,PLUGIN_STATUS from information_schema.plugins where plugin_name like &apos;%semi%&apos;; #启用半同步复制,临时生效 #设置全局主服务器 set global rpl_semi_sync_master_enabled=1; #设置全局从服务器 set global rpl_semi_sync_slave_enabled=1; #查询是否开启(ON) show variables like &apos;%rpl_semi_sync%enabled%&apos;; #设置永久配置 vim /etc/my.cnf plugin-load=rpl_semi_sync_master=semisync_master.so rpl_semi_sync_master_enabled=1 plugin-load=rpl_semi_sync_slave=semisync_slave.so rpl_semi_sync_slave_enabled=1 ####安装maxscale服务 maxscale代理软件 maxscale.cnf 配置文件 maxscale.cnf.template模板 maxscale.modules.d/ 模块 ls /var/log/maxscale/ 日志 10 threads=1 改为auto 线程运行数量,自动获取 18 [server1] [server12 指定IP,端口 [MySql Monitor] 定义要监听的数据库节点 [Read-Write Service] 定义读写分离的数据库节点 配置用户名密码时:检测客户端访问的用户是否存在 [Read-Write-Listener] 定义读写分离服务端口 port=4006 [MaxAdmin Listener] 定义管理服务端口号 添加port=4016 //创建监控用户 grant replication slave ,replication client on *.* to maxscalemon@&apos;%&apos; identified by &apos;1qaz@WSX&apos;; //创建路由用户 grant select on mysql.* to maxscalrou@&apos;%&apos; identified by &apos;1qaz@WSX&apos;; //启动进程 查看端口 停止服务 maxscale -f /etc/maxscale.cnf netstat -untup|grep maxscale kill -9 pid号 ##测试连接 57 maxadmin -uadmin -pmariadb -P4016 MaxScale&gt; list servers 客户端 mysql -h192.168.4.57 -P4006 -uyaya888 -p1qaz@WSX 在从插入数据,用主查询(没数据),用客户端查询(有数据).此时说明数据库读的是从服务器 ####多实例服务 为什么要使用多实例? 节约成本,提高硬件利用率 配置多实例. 安装软件包libaio,解压源码包mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz mv mysql-5.7.20-linux-glibc2.12-x86_64 /usr/local/mysql useradd mysql echo $PATH PATH=/usr/local/mysql/bin/:$PATH vim /etc/profile export PATH=/usr/local/mysql/bin:$PATH 套接字文件sock vim /etc/my.cnf [mysqld_multi] #启用多实例 mysqld = /usr/local/mysql/bin/mysqld_safe #指定进场文件路径 mysqladmin = /usr/local/mysql/bin/mysqladmin #指定管理命令路径 user = root #指定进场用户 [mysqld1] #实例进程名称 port = 3307 #端口号 datadir = /dir1 #数据库目录,需要手动创建 socket = /dir1/mysql1.sock #指定sock文件的路径和名称 pid-file = /dir1/mysqld.pid #进场pid号文件位置 log-error = /dir1/mysqld.err #错误日志位置 [mysqld2] port = 3308 datadir = /dir2 socket = /dir2/mysql2.sock pid-file = /dir2/mysqld.pid log-error = /dir2/mysqld.err mkdir /dir{1,2} mysqld_multi start 1 #启动服务 #修改密码 mysql -uroot -p&apos;vxBssOy:C1f?&apos; -S /dir1/mysql1.sock mysql -uroot -p&apos;y0jD-NW&gt;M=i/&apos; -S /dir2/mysql2.sock alter user root@&quot;localhost&quot; identified by &apos;123456&apos;; mysqld_multi --user=root --password=密码 stop 实例编号 #停止服务 grant all on *.* to ceshi@&quot;%&quot; identified by &apos;1qaz@WSX&apos;; 客户端访问 mysql -h192.168.4.60 -P3307 -uroot -p123456 mysql -h192.168.4.60 -P3308 -uceshi2 -p1qaz@WSX ###Day ####数据分片 环境: 1台客户端 1台分布式 3台服务端工作流程 当mycat收到一个SQL命令时 1.解析SQL命令涉及到的表 2.然后看对表的配置,如有分片规则,则获取SQL命令里分片字段的值,并匹配分片函数,获取分片列表 3.然后将SQL命令发往对应的分片服务器去执行 4.最后收集和处理所有分片结果数据,并返回到客户端安装软件 java-1.8.0-openjdk mycat usr/local/mycat/ bin //mycat命令 catlet //扩展功能 conf //配置文件 lib //mycat使用的jar包 logs //mycat启动日志和运行日志 (wrapper.log //mycat服务启动日志 mycat.log //记录SQL脚本执行后的报错内容) mycat服务配置文件 rule.xml 分片规则 server.xml 设置连接账号及逻辑库 schema.xml 配置数据分片部署mycat vim /usl/local/mycat/conf/server.xml #里面包含远程登录用户名密码 配置/usl/local/mycat/conf/schema.xml服务 配置数据分片的表 &lt;schema&gt; //定义分片信息 &lt;table&gt; //定义表 name //逻辑库名或逻辑表名 dataNode //指定数据节点名 rule //指定使用的分片规则 type=global //数据不分存储 &lt;dataNode 选项=值&gt; //定义数据节点 name //数据节点名 datahost 数据库服务器主机名 database 数据库名 定义数据库服务器IP地址及端口 &lt;datahost 选择=值&gt; //服务器主机名 name //主机名(与datahost对应的主机名) host //主机名(与IP地址对应的主机名) url //数据库服务器IP地址及端口号 user //数据库服务器授权用户 password //授权用户密码配置数据库服务器 添加授权用户 创建存储数据 数据库db1 db2 db3 启动服务 /usr/local/mycat/bin/mycat –help Usage: /usr/local/mycat/bin/mycat { console | start | stop | restart | status | dump } netstat -antup|grep 8066客户端连接 mysql -h192.168.4.56 -P8066 -uroot -p123456 ####分片规则枚举法(sharding-by-intfile) 字段值必须在列举范围内选择 1. /usr/local/mycat/conf/rule.xml &lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-intfile&quot; /&gt; 2. usr/local/mycat/conf/rule.xml &lt;tableRule name=&quot;sharding-by-intfile&quot;&gt; &lt;rule&gt; &lt;columns&gt;sharding_id&lt;/columns&gt; &lt;algorithm&gt;hash-int&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name=&quot;hash-int&quot; class=&quot;io.mycat.route.function.PartitionByFileMap&quot;&gt; &lt;property name=&quot;mapFile&quot;&gt;partition-hash-int.txt&lt;/property&gt; &lt;/function&gt; 3. vim conf/partition-hash-int.txt 10000=0 10010=1 10020=2 添加,由于配置dns1,dns2,dns3需要添加 创建表 create table employee (id int primary key auto_increment , sharding_id int , name varchar(10),sex enum (&quot;m&quot;,&quot;w&quot;)); ##插入数据验证 求模法(mod-long) 根据字段值与设定的数字求模结果存储数据 1. /usr/local/mycat/conf/rule.xml &lt;table name=&quot;hotnews&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;mod-long&quot; /&gt; 2. usr/local/mycat/conf/rule.xml &lt;tableRule name=&quot;mod-long&quot;&gt; &lt;rule&gt; &lt;columns&gt;id&lt;/columns&gt; &lt;algorithm&gt;mod-long&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name=&quot;mod-long&quot; class=&quot;io.mycat.route.function.PartitionByMod&quot;&gt; &lt;!-- how many data nodes --&gt; &lt;property name=&quot;count&quot;&gt;3&lt;/property&gt; &lt;/function&gt; create table hotnews(id int ,title char(20),worker char (15), comment varchar(50),fb_time timestamp); mysql&gt; insert into hotnews (id,title,worker,comment,fb_time) values (3,&apos;aa&apos;,&quot;bb&quot;,&apos;sdfasdf&apos;,now()); 全局 create table company (id int primary key auto_increment,gname char(10),money int ,peploe char(10),gaddr char(50)); inse company (gname,money,peploe,gaddr) values (&apos;tedu&apos;,10000,&apos;aa&apos;,&apos;beijing&apos;); 3台服务器均匀数据 添加新库新表 server.xml &lt;user name=&quot;root&quot;&gt; &lt;property name=&quot;password&quot;&gt;123456&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB,BBSDB&lt;/property&gt; &lt;/user&gt; schema.xml &lt;schema name=&quot;BBSDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;table name=&quot;enmployee2&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;sharding-by-intfile&quot; /&gt; &lt;table name=&quot;company2&quot; primaryKey=&quot;ID&quot; type=&quot;global&quot; dataNode=&quot;dn1,dn2,dn3&quot; /&gt; &lt;/schema&gt; Day MHA组成 MHA Manager(管理节点) 管理所有数据库服务器 可以单独部署在一台独立的机器上 也可以部署在某台数据库服务器上 MHA Node(数据节点) 存储数据库的mysql服务器 运行在每台mysql服务器上 MHA工作过程 由Manager定时探测集群中的master节点 当master故障时,Manager自动将拥有最新数据的slave提升为新的master配置环境 安装prel包 perl-* 配置免登陆秘钥 配置1主2从 管理集群命令 ls /rootperl5/bin/masterha_* masterha_check_ssh 检查MHA的SSH配置状况 masterha_checkrepl 检查MySQL复制状况 masterha_manager 启动MHA masterha_check_status 检测MHA运行状态 masterha_stop 停止MHA安装软件包 mha4mysql-manager-0.56.tar.gz(管理服务器,数据库服务器) perl Makefile.pl make &amp;&amp; make install mha4mysql-node-0.56-0.el6.noarch.rpm(数据库服务器) 存在依赖关系需要安装其他软件包 garnt all on *.* to root@&quot;%&quot; identified by &quot;1qaz@WSX&quot;; //监控用户 grant replication slave on *.* to aaa@&quot;%&quot; identified by &apos;1qaz@WSX&apos;; //数据同步用户编写主配置文件 模板文件 mkdir /mha vim /mha/app1.cnf [server default] //管理服务默认配置anager_log=/mha/manager.log //日志文件anager_workdir=/mha //工作目录aster_ip_failover_script=/mha/master_ip_failover //故障切换脚本 repl_password=1qaz@WSX //主服务器数据同步授权用户repl_user=aaa //密码 ssh_port=22 //ssh服务端口ssh_user=root //访问ssh服务器用户 user=root //监控用户password=1qaz@WSX //密码 [server1] //指定第一台数据库服务器candidate_master=1 //竞选主服务器hostname=192.168.4.51 //服务器IPport=3306 //服务端口 [server2]……[server3] 创建故障切换脚本y $vip = ‘192.168.4.100/24’; # Virtual IP //定义VIP地址y $key = “1”; //定义地址编号y $ssh_start_vip = “/sbin/ifconfig eth0:$key $vip”; //绑定VIP地址y $ssh_stop_vip = “/sbin/ifconfig eth0:$key down”; //释放VIP地址部署VIP地址 在主库 部署vip地址(51主服务器设置VIP地址192.168.4.100) ifconfig eth0:1 192.168.4.100(临时,重启机器则会没掉) 查看vip地址 ifconfig eth0:1 或ip addr show eth0 51主服务器启用半同步复制,及禁止自动删除中继日志文件(默认中继日志文件保留近2天. vim /etc/my.cnf 开启log-bin plugin-load=rpl_semi_sync_master=semisync_master.so rpl_semi_sync_master_enabled=1 plugin-load=rpl_semi_sync_slave=semisync_slave.so rpl_semi_sync_slave_enabled=1 relay_log_purge=0 或 plugin-load=&quot;rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so&quot; 52 53启用半同步复制模式 及禁用自动删除中继日志文件 vim /etc/my.cnf log-bin=master52 server_id=52 relay_log_purge=0 plugin-load=&quot;rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so&quot; rpl_semi_sync_master_enabled=1 rpl_semi_sync_slave_enabled=1 配置主从结构 change master …… ####测试配置 测试ssh配置 masterha_check_ssh --conf=/mha/app1.cnf Fri Oct 18 15:48:11 2019 - [info] All SSH connection tests passed successfully. 测试主从同步配置 masterha_check_repl --conf=/mha/app1.cnf MySQL Replication Health is OK. ####启动管理服务 masterha_manager --conf=/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover --remove_dead_master_conf //删除宕机主库的配置 --ignore_last_failover //忽略xxx.health文件 查看状态 masterha_check_status --conf=/mha/app1.cnf 停止服务 masterha_stop --conf=/mha/app1.cnf 访问集群 主服务器添加库创建表,插入数据,2台从服务器查看用户 客户端访问VIP地址 mysql -h192.168.4.100 -uyay -p1qaz@WSX 测试高可用 停止mysql服务 从服务器看 ifconfig eth0:1 aap1.cnf无server1信息 修复故障服务器 启动mysql服务 与主服务器数据一致 指定主服务器信息 启动slave进程 查看状态信息 具体操作: 修改主配置文件 测试集群环境 重启管理服务 查看服务状态 Day PXC特点 数据强一致性,无同步延迟相关配置文件 /etc/percona-xtradb-cluster.conf.d/ mysqld.cnf #数据库服务运行参数配置 mysqld_safe.cnf #Percona Server5.7配置文件 wsrep.cnf #PXC集群配置文件 3306 数据库服务端口 4567 集群通信端口 4444 SST端口 4568 IST端口 SST State Snapshot Transfer 全量同步 iST Incremental State Transfer 增量同步 主机名映射 安装 #!/bin/bash cd /root/PXC yum -y install libev-4.15-1.el6.rf.x86_64.rpm percona-xtrabackup-24-2.4.13-1.el7.x86_64.rpm qpress-1.1-14.11.x86_64.rpm mkdir percona;tar -xf Percona-XtraDB-Cluster-5.7.25-31.35-r463-el7-x86_64-bundle.tar -C percona cd percona/ ;yum -y install Percona-XtraDB*.rpm vim /etc/percona-xtradb-cluster.conf.d/mysqld.cnf 修改server_id vim /etc/percona-xtradb-cluster.conf.d/wsrep.cnf 8 wsrep_cluster_address=gcomm://192.168.4.71,192.168.4.72 集群成员列表 27 wsrep_cluster_name=pxc-cluster 集群名称 需一致默认即可 25 wsrep_node_address=192.168.4.71 本机IP 30 wsrep_node_name=pxc71 本机主机名 39 wsrep_sst_auth=&quot;sstuser:1@qazWSX&quot; 全量认证时同步用户名密码 启动程序 [root@71 percona-xtradb-cluster.conf.d]# ll /var/lib/mysql 总用量 0 启动程序 systemctl start mysql@bootstrap.service 日志文件查询密码,登入修改密码 添加授权 grant reload,lock tables,replication client,process on *.* to sstuser@&quot;localhost&quot; identified by &apos;1qaz@WSX&apos;; #或者直接all所有权限 剩余机器启动服务 systemctl start mysql 数据,授权数据都会增量同步过来 netstat -antu|grep -E &apos;3306|4567&apos; 检查配置 show status like &apos;%wsrep%&apos;; wsrep_incoming_addresses | 192.168.4.73:3306,192.168.4.71:3306,192.168.4.72:3306 | #成员列表 wsrep_cluster_size | 3 #集群服务器台数 wsrep_cluster_status | Primary #集群状态 wsrep_connected | ON #连接状态 wsrep_ready | ON #服务状态 测试高可用 停止某一台机器服务.插入数据,在恢复查询是否恢复 如果停止71进程 systemctl stop mysql@bootstrap.service 恢复需要修改配置文件取消192.168.4.71.在启动.添加192.168.4.71在启动进程. PS:测试恢复不需要改配置文件,数据仍可同步过来 MySQL存储引擎 MySQL 5.0/5.1--&gt; MyISAM MySQL 5.5/5.6--&gt; InnoDB show engines; #列出可用的存储引擎 未指定时,使用默认存储引擎 alter table 表名 engine=存储引擎名 修改服务存储引擎 /etc/my.cnf default-storage-engine=存储引擎 myisam存储引擎 主要特点: 支持表级锁 不支持事物,事物回滚,外键innodb存储引擎 主要特点: 支持行级锁定 支持事物,事物回滚,外键 事物日志文件 ibdate1 ib_logfile0 ib_logfile1MySQL锁机制 锁粒度 表级锁:对整张表加锁 行级锁:仅对被访问的行分别加锁 锁类型 读锁(共享锁):支持并发读 写锁(互斥锁,排它锁):是独占锁,上锁期间其他线程不能读表或写表 查看当前锁状态 show status like ‘table_lock%’; Redis 初始配置 ./utils/install_server.sh –端口 6379 –主配置文件 /etc/redis/6379.conf –日志文件 /var/log/redis_6379.log –数据库目录 /var/lib/redis/6379 –服务启动程序 /usr/local/bin/redis-server –命令行连接命令 /usr/local/bin/redis-cli 管理服务 /etc/init.d/redis_6379 stop /etc/init.d/redis_6379 start ps -C redis-server netstat -utnlp | grep :6379 常用命令 set key名 key值 //存储1个key值 mset key名列表 //存储多个key值 get key名 //获取key值 mget //获取多个key值 select 数据库编号0-15 //切换库(配置文件里面可设置) keys * //显示所有key名 keys a? //显示指定key名 exists key名 //测试key名是否存在 ttl key名 //查看key生存时间 type key名 //查看key类型 move key名 库编号 //移动key到指定库 expire key名 数字 //设置key有效时间 del key名 //删除指定的key flushall //删除内存里面所有key flushdb //删除所在库的所有key sava //保存所有key到硬盘 shutdown //停止服务 配置分类 NETWORK 网络 GENERAL 常规 SNAPSHOTTING 快照 REPLICATION 复制 SECURITY 安全 CLIENTS 客户端 MEMORY MANAGEMENT 内存管理常用配置 port 6397 端口 bind 127.0.0.1 IP地址 deamonize yes 守护进程方式运行 databases 16 数据库个数 logfile /var/log/redis_6379.log 日志文件 maxclients 10000 并发连接数量 dir /var/lib/redis/6379 数据库目录 wget http://download.redis.io/releases/redis-5.0.4.tar.gz rpm -q gcc||yum -y install gcc tar -xzvf redis-5.0.4.tar.gz cd redis-5.0.4/ make &amp;&amp; make install ./utils/install_server.sh redis-cli -h 127,., .0.0.1 -p 65535 set school tarena redis-cli -h 127.0.0.1 -p 65535 get school 部署lnmp+redis yum -y install gcc pcre-devel zlib-devel tar -zxf nginx-1.12.2.tar.gz cd /nginx-1.12.2/ ./configure make &amp;&amp; make install vim /usr/local/nginx/conf/nginx.conf /usr/local/nginx/sbin/nginx yum -y install php php-fpm systemctl restart php-fpm systemctl enable php-fpm tar -xzf php-redis-2.2.4.tar.gz cd phpredis-2.2.4/ phpize ./configure --with-php-config=/usr/bin/php-config make &amp;&amp; make install ll /usr/lib64/php/modules/ vim /etc/php.ini 728 extension_dir = &apos;目录名&apos;; 730 extension = &apos;模块名&apos;; systemctl restart php-fpm php -m |grep -i redis //检查是否支持模块 redis集群(分布式高可用集群 ,同时能够实现数据自动同步) ###创建集群 1.部署管理主机 1.1部署ruby脚本运行环境 ruby 解释ruby程序 rubygems 提供连接程序软件 yum -y install rubygems gem install redis-3.2.1.gem 1.2创建管理集群脚本 tar -xzf redis-5.0.4.tar.gz //5版本可能存在问题 cd redis-5.0.4/ mkdir /root/bin cp src/redis-trib.rb /root/bin/2.创建集群 1.1创建集群 配置6台redis服务器 vim /etc/redis/6379.conf cluster-enabled yes //启用集群功能 815s cluster-config-file nodes-6379.conf //存储集群信息文件 823s cluster-node-timeout 5000 //连接超时时间(毫秒) 829s 重启redis服务 检查端口,集群通信端口=默认服务端口+10000 redis-trib.rb create –replicas 1 192.168.4.51:6351 192.168.4.52:6352 192.168.4.53:6353 192.168.4.54:6354 192.168.4.55:6355 192.168.4.56:6356 –replicas 1(指从库) ,默认3主 如果填2则时1主2从. 对应配置文件/var/lib/redis/6379/nodes-6379.conf 1.2检查集群 redis-cli -h 192.168.4.52 -p 6352 cluster info 查看集群节点信息 redis-cli -h 192.168.4.52 -p 6352 cluster nodes 管理服务器执行:redis-trib.rb info //检查集群主机角色 redis-trib.rb check 192.168.4.51:6351 ###创建集群 1.测试集群功能 任意停掉一台master服务器redis服务 –master宕机后对应的slave自动被选举为master –原master启动后会自动配置为当前master的slave 检测集群 redis-trib.rb check 192.168.4.51:6351 redis-trib.rb info 192.168.4.51:6351 2.添加服务器 添加master主机 2.1部署redis服务 安装gcc 解压redis源码包 make &amp;&amp; make install ./utils/install_server.sh 修改配置文件:地址,端口,开起集群功能 重启服务 netstat 检查2个端口 2.2添加master主机步骤 添加master主机时不指定主机角色,默认新主机被选为master 添加的master直接,需要手动分片hash槽 redis-trib.rb add-node 192.168.4.58:6358 192.168.4.51:6351 redis-trib.rb reshard 192.168.4.51:6351 重新分片问题 -移除hash槽个数 -接收hash槽主机ID -移除hast槽主机ID 添加slave主机 部署redis服务 添加slave主机 redis-trib.rb add-node –slave 192.168.4.59:6359 192.168.4.51:6351 2.3删除集群中的redis服务器 删除master服务器 -释放占用的hash槽 -移除主机 删除slave服务器 -从服务器没有hash槽,直接移除即可. -移除时指定从服务器id值. -移除后会停止从服务器进程 redis-trib.rb del-node 任意ip端口 从ID 5c3bd81d07c43e5e05ee931f035493ee18fb5092 2.4把删除的redis服务,在添加到集群里 -启动被删除的redis服务 192.168.4.58:6358&gt; cluster reset 或者删除配置文件/var/lib/redis/6379/nodes-6379.conf 2.5删除集群服务恢复独立redisexpire.sh redis-trib.rb rebalance 任意ip端口 //重新平均分片槽 Day 1.redis主从复制 1.1结构模式 一主一从 一主多从 主从从 配置 redis本身就是master,所以无需配置 192.168.4.52:6352&gt; slaveof 192.168.4.51 6351 从配置即可,配置完立即生效 192.168.4.52:6352&gt; SLAVEOF no one 取消主从关系 info replication 查看复制信息 永久配置修改配置文件 /etc/redis/6379.conf ######## REPLICATION ############## redis 4版本 # slaveof redis 5版本 # 289 replicaof 192.168.4.51 6351 添加密码设置 ######### SECURITY ###### # requirepass foobared //配置master,定义连接密码 295 # masterauth &lt;master-password&gt; //配置slave,主库密码 命令行也可以配置 config get masterauth 配置项 config set masterauth 配置项 值 config rewrite //保存到配置文件 哨兵服务 客户端安装redis即可 yum -y install gcc tar -xzf redis-4.0.8.tar.gz make &amp;&amp; make install 无需初始化. ##编辑配置文件,可以参考edis-4.0.8/sentinel.conf cp redis-4.0.8/sentinel.conf /etc/ bind 0.0.0.0 ip允许所有 port 26379 端口 sentinel monitor server51 192.168.4.51 6351 1 sentinel auth-pass server51 123456 有密码可以设置 ##启动程序 redis-sentinel /etc/sentinel.conf 数据持久化 RDB 按照指定时间间隔,将内存中的数据集快照写入硬盘 192.168.4.50:65535&gt; config get dbfilename /var/lib/redis/6379/dump.rdb 219 save 900 1 //15分钟且有一个key改变 220 save 300 10 //5分钟且有10个key改变 221 save 60 10000 //1分钟且有10000个key改变 254 dbfilename dump.rdb 手动存盘 -save //阻塞写存盘 -bgsave //不阻塞写存盘 备份数据 备份dump.rdb 文件到其他位置 恢复数据 拷贝备份文件到数据库目录,重启redis服务 RDB 的优缺点 优点： 1 适合大规模的数据恢复。 2 如果业务对数据完整性和一致性要求不高，RDB是很好的选择。 缺点： 1 数据的完整性和一致性不高，因为RDB可能在最后一次备份时宕机了。 2 备份时占用内存，因为Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍哦），最后再将临时文件替换之前的备份文件。 所以Redis 的持久化和数据的恢复要选择在夜深人静的时候执行是比较合理的。 AOF 追加方式记录写操作的文件 记录reids服务所有写操作 不断的将新的写操作,追加到文件的末尾 默认没有启用 使用cat命令可以查看文件内容 启动AOF 192.168.4.50:65535&gt; config get appendonly config set appendonly yes //启用aof,默认no config rewrite 704 appendfilename &quot;appendonly.aof&quot; //日志文件名 备份数据appendonly.aof文件到其他位置 cp 数据库目录/appendonly.aof 备份目录 恢复数据 拷贝备份文件到数据库目录 重启redis服务 729 # appendfsync always //时时记录,并完成磁盘同步 730 appendfsync everysec //每秒记录一次,并完成磁盘同步(默认) 731 # appendfsync no //写入aof,不执行磁盘同步 771 auto-aof-rewrite-percentage 100 //再次重写,增长百分比 772 auto-aof-rewrite-min-size 64mb //首次重写触发值 修复AOF文件 redis-check-aof --fix /var/lib/redis/65535/appendonly.aof AOF 的优缺点 优点：数据的完整性和一致性更高 缺点：因为AOF记录的内容多，文件会越来越大，数据恢复也会越来越慢。 string 字符串 set 参数如下: ex 秒 px 毫秒 默认永不过期 nx 不存在赋值 xx存在赋值 (默认) 2.192.168.4.55:6355&gt; set zhj ABCDEF OK 192.168.4.55:6355&gt; setrange zhj 2 XX ##从偏移量开始复写key的特定位的值 (integer) 6 192.168.4.55:6355&gt; get zhj &quot;ABXXEF&quot; 192.168.4.55:6355&gt; strlen zhj ##统计字串长度 (integer) 6 192.168.4.55:6355&gt; append zhj G ##存在则追加,不存在则创建key及value,返回key长度 (integer) 7 192.168.4.55:6355&gt; get zhj &quot;ABXXEFG&quot; 3.setbit key offset value -对key所存储字串,设置或清除特定偏移量上的位(bit) -value值可以为1或0,offset为0~2^32之间 -key不存在,则创建新的key set a 0 1 4.bitcount key -统计字串中被设置为1的比特位数量 bitcount a 5.dcer key -将key中的值减1,key不存在则先初始化为0,在减1 set test 10 decr test 6.decrby key decrement 将key中的值,减去decrement set aa 200 decrby aa 20 7.getrange key start end -返回字串值中的子字串,截取范围为start和end -负数偏移量表示从末尾开始计数,-1表示最后一个字符,-2表示倒数第二个 set aa ABCDF getrange aa 0 2 //ABC getrange aa -3 -1 //CDF 8.incr key 将key的值加1,如果key不存在,则初始化为0后面加1 set aa 9.incrby key increment 将key的值增加increment incrby aa 10 10.incrbyfloat key increment -为key中所存储的值加上浮点数增量increment set num 17.8 incrbyfloat num 1.2 11.meget key 获取一个或多个key值,空格分隔,具有原子性 12.mset key value 设置多个key及值,空格分隔,具有原子性 List列表 1. lpush list aa bb cc dd ee 2. llen list 3. lrange list 0 -1 4. lpop list 5. lindex list 1 6. lset list 1 zhj 7. rpush test 1 8. rpop testHash表 1.将hash表中field设置为value hset hash baidu www.baidu.com 2.同时给hash表中多个field赋值 HMSET hash aa www.aa.com bb www.bb.com 3.返回hash表中多个field的值 hmget hash baidu jd 4.获取hash表中的field值 hget hash baidu ====&quot;www.baidu.com&quot; 5.查询hash表中所有field名称 hkeys hash 6.返回hash表中所有field值 hgetall hash 7.返回hash表中所有filed的值 hvals key 8.删除hash表中多个field hdel key zlib 数据压缩–nodeps rpm在安装/卸载时，不检查依赖关系","permalink":"114.55.64.175/2019/11/mysql/","photos":[]},{"tags":[],"title":"kibana","date":"2019/11/16","text":"// This is some text! 安装elasticsearch软件包java-1.8.0-openjdk elasticsearch配置文件/etc/elasticsearch/elasticsearch.yml 17 cluster.name: myelk //配置集群名字 23 node.name: es1 //当前主机名称 54 network.host: 0.0.0.0 // 0.0.0.0（监听所有地址） 68 discovery.zen.ping.unicast.hosts: [“es1”, “es2”, “es3”] //声明集群里的主机成员有谁，不需要全部写进去(hosts需要配置) 配置好,启动服务,发现9200,9300被监听.curl ip:9200即可ES集群配置更改配置文件node.name即可curl http://192.168.1.51:9200/_cluster/health?pretty 安装包 插件 名称 elasticsearch-head-master.zip //安装head插件 elasticsearch-kopf-master.zip //安装kopf插件 bigdesk-master.zip //安装bigdesk插件 ./plugin install //安装插件 ./plugin list //查看安装的插件 访问插件 curl http://192.168.1.55:9200/_plugin/xxx (head) 安装kibana软件包kibana-4.5.2-1.x86_64配置文件/opt/kibana/config/kibana.yml 2 server.port: 5601 #端口 5 server.host: “0.0.0.0” #地址 15 elasticsearch.url: “http://es1:9200&quot; #数据库地址 23 kibana.index: “.kibana” #创建索引的名称,数据库可以查询 26 kibana.defaultAppId: “discover” #默认首页 53 elasticsearch.pingTimeout: 1500 #ping超时 57 elasticsearch.requestTimeout: 30000 #请求超时 64 elasticsearch.startupTimeou #启动超时 启动服务systemctl restart kibana 帮助文档path =&gt; “” 文件路径start_position string, one of [“beginning”, “end”] Nosincedb_path string No指针文件 /var/lib/logstash/since.db 标识上一次读到哪里,下次重断掉位置继续读(文件会自动创建)type =&gt; “” 日志类型标签(随便写) 配置文件cat /etc/logstash/logstash.conf input { file { path =&gt; [“/tmp/a.log”] start_position =&gt; “beginning” sincedb_path =&gt; “/var/lib/logstash/since.db” type =&gt; “a_log” } } filter{ } utput { stdout { codec =&gt; “rubydebug”} } 执行测试 /opt/logstash/bin/logstash -f /etc/logstash/logstash.conf [root@es5 ~]curl -XDELETE “http://es1:9200/*&quot; filter grok插件安装配置filebeat配置文件路径:/etc/filebeat/filebeat.yml 正则宏路径 vim /opt/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns/grok-patterns 12aaaabbb","permalink":"114.55.64.175/2019/11/kibana/","photos":[]},{"tags":[],"title":"page","date":"2019/11/13","text":"","permalink":"114.55.64.175/2019/11/about/me/","photos":[]},{"tags":[],"title":"ansible","date":"2019/11/13","text":"#!/bin/bashyum -y install gcc pcre-devel curl-devel net-snmp-devel libevent-develcd /usr/local/srctar -xf zabbix-3.4.4.tar.gzcd zabbix-3.4.4./configure –enable-agent#–with-net-snmp –with-libcurl –enable-agentmake installsed -i ‘s/^Server/#Server/‘ /usr/local/etc/zabbix_agentd.confsed -i ‘s/# StartAgents=3/StartAgents=0/‘ /usr/local/etc/zabbix_agentd.confsed -i ‘s/# ServerActive=/ServerActive=192.168.1.40/‘ /usr/local/etc/zabbix_agentd.confsed -i ‘s/Hostname=Zabbix server/Hostname=db1/‘ /usr/local/etc/zabbix_agentd.confsed -i ‘s/# RefreshActiveChecks=120/RefreshActiveChecks=120/‘ /usr/local/etc/zabbix_agentd.conf","permalink":"114.55.64.175/2019/11/zabbix/","photos":[]}]}